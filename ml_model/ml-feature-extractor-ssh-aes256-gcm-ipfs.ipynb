{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, MaxPool2D, AvgPool2D, Dense, Conv2D, Normalization, BatchNormalization, Flatten, Dropout, Input, Activation, Concatenate, Multiply, Add, Input\nfrom tensorflow.keras.models import Model\n\ninput = Input(shape= (512,512,3))\nx = Conv2D(512, (3,3), padding=\"same\", dilation_rate=(1,1), activation='relu')(input)\nx = BatchNormalization()(x)\n\nx1 = Conv2D(256, (3,3), padding=\"same\", activation='relu')(x)\nx1 = BatchNormalization()(x1)\n\nx2 = Conv2D(128, (3,3), padding=\"same\", activation='relu')(x1)\nxc1 = Concatenate()([input,x1,x2])\nxa1 = Activation('sigmoid')(xc1)\n\nxi1 = Conv2D(387, (1,1), padding=\"same\", activation='relu')(input)\nxad = Add()([xa1,xi1])\n\nx3 = Conv2D(256, (3,3), padding=\"same\", activation='relu')(xad)\n\nx3 = MaxPool2D()(x3)\nx4 = Conv2D(128, (3,3), padding=\"same\", activation='relu')(x3)\nx4 = BatchNormalization()(x4)\nx5 = Conv2D(64, (3,3), padding=\"same\", activation='relu')(x4)\nx5 = BatchNormalization()(x5)\nxc2 = Concatenate()([x4,x5])\nx0 = Conv2D(128, (3,3), padding=\"same\", activation='relu')(xc2)\nx5 = BatchNormalization()(x0)\nxa2 = Activation('sigmoid')(x5)\n\nxi2 = Conv2D(128, (1,1), strides=(2,2), padding=\"same\", activation='relu')(input)\nxad2 = Add()([xa2,xi2])\n\nx6 = Conv2D(128, (3,3), strides=(2,2), padding=\"same\", activation='relu')(xad2)\nx6 = BatchNormalization()(x6)\nx6 = Conv2D(64, (3,3), padding=\"same\", activation='relu')(x6)\nx6 = BatchNormalization()(x6)\nx6 = MaxPool2D()(x6)\nx6 = BatchNormalization()(x6)\n\nxi3 = Conv2D(64, (1,1), strides=(8,8), padding=\"same\", dilation_rate=(1,1), activation='relu')(input)\nxad3 = Add()([x6,xi3])\n\nx7 = Conv2D(32, (3,3), strides=(2,2), padding=\"same\", activation='relu')(xad3)\nx7 = AvgPool2D(2,2)(x7)\nx7 = Conv2D(16, (3,3), padding=\"same\", activation='sigmoid')(x7)\nout = Conv2D(8, (3,3),  padding=\"same\", activation='softmax')(x7)\nmodel = Model(input, out)\nmodel.summary()\nmodel.save('model.h5')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Map Extractor","metadata":{}},{"cell_type":"code","source":"# model = tf.keras.models.load_model('model.h5')\ndef featureMapExtractor(img_path):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(512, 512))\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = tf.expand_dims(img_array, axis=0)\n    feature_maps = model.predict(img_array)\n    feature_map = feature_maps[0, :, :, 0]\n    min_value = np.min(feature_map)\n    max_value = np.max(feature_map)\n    normalized_feature_map1 = (feature_map - min_value) / (max_value - min_value)\n    return np.where(normalized_feature_map1 > 0.6, 1, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encryption AES256 GCM","metadata":{}},{"cell_type":"code","source":"from Crypto.Cipher import AES\nfrom Crypto.Random import get_random_bytes\n\ndef encrypt_image(image_path_cmp):\n    key = get_random_bytes(32)\n    with open(image_path_cmp, 'rb') as file:\n        original_data = file.read()\n\n    cipher = AES.new(key, AES.MODE_GCM)\n    ciphertext, tag = cipher.encrypt_and_digest(original_data)\n\n    file_out = image_path_cmp + '.enc'\n    with open(file_out, 'wb') as file:\n        [ file.write(x) for x in (cipher.nonce, tag, ciphertext) ]\n    return file_out, key\n\ndef decrypt_image(key, encrypted_image_path):\n    with open(encrypted_image_path, 'rb') as file:\n        nonce, tag, ciphertext = [ file.read(x) for x in (16, 16, -1) ]\n\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    data = cipher.decrypt_and_verify(ciphertext, tag)\n    \n    file_out = encrypted_image_path[:-4]  \n    with open(file_out, 'wb') as file:\n        file.write(data)\n    return file_out\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IPFS","metadata":{}},{"cell_type":"code","source":"import requests\nimport os\nfrom dotenv import load_dotenv\nimport pprint\n\nPINATA_JWT_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySW5mb3JtYXRpb24iOnsiaWQiOiJhNWRiODU0MS1kOTMxLTQzNmMtYjhkYy00M2Q3NWJjN2JiZTEiLCJlbWFpbCI6InllYXNpcjQwMkBnbWFpbC5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwicGluX3BvbGljeSI6eyJyZWdpb25zIjpbeyJpZCI6IkZSQTEiLCJkZXNpcmVkUmVwbGljYXRpb25Db3VudCI6MX0seyJpZCI6Ik5ZQzEiLCJkZXNpcmVkUmVwbGljYXRpb25Db3VudCI6MX1dLCJ2ZXJzaW9uIjoxfSwibWZhX2VuYWJsZWQiOmZhbHNlLCJzdGF0dXMiOiJBQ1RJVkUifSwiYXV0aGVudGljYXRpb25UeXBlIjoic2NvcGVkS2V5Iiwic2NvcGVkS2V5S2V5IjoiNTZjNDZlOTI1MDMxZTI4MDFmNzEiLCJzY29wZWRLZXlTZWNyZXQiOiJkMmQ4ODFiNTM0N2FkOThkMmUwNTJjYjIyNmVjN2FmMmQxN2Q1ZDU4N2MzM2MyODI5OTBhZWZhMzI4NTQwZDFmIiwiaWF0IjoxNzE0MDI4MDYwfQ.1QlnRLCkvAHq7IIshtNFORl0l-D3sYGD_8l786PQqYE\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def upload_to_pinata_ipfs(encrypted_img):\n    url = \"https://api.pinata.cloud/pinning/pinFileToIPFS\"\n    headers = {'Authorization': f'Bearer {PINATA_JWT_TOKEN}'}\n\n    with open(encrypted_img, 'rb') as file:\n        response = requests.post(url,files={'file':file},headers=headers)\n        return \"https://ipfs.io/ipfs/\"+response.json()['IpfsHash']\n\n    return response.json()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, requests\ndef download_from_ipfs(ipfs_url):\n    response = requests.get(ipfs_url)\n    if response.status_code != 200:\n        raise Exception(\"Failed to download file from IPFS\")\n    \n    output_dir = '/kaggle/working'\n    encrypted_img_path = os.path.join(output_dir, 'encrypted_image.jpeg.enc')\n    with open(encrypted_img_path, 'wb') as file:\n        file.write(response.content)\n    \n    return encrypted_img_path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# download_from_ipfs('https://ipfs.io/ipfs/QmTKg7RaAqrpw1pidBjSh88yeNzU9ekLg4MueCef2zMY7d')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Flask","metadata":{}},{"cell_type":"code","source":"!pip install pyngrok","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install flask_cors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyngrok import ngrok\nngrok_key = \"2h6aGsbaomJpD9RNn1hfjhVHycV_2vDU8c4vhSWrdws92oJik\"\nport = 5000\nngrok.set_auth_token(ngrok_key)\nngrok.connect(port).public_url","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from flask import Flask, jsonify, request, render_template_string \nimport numpy as np\nfrom PIL import Image\nimport binascii\nimport base64\nfrom io import BytesIO\nfrom flask_cors import CORS  \nimport time\n\napp = Flask(__name__)\nCORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n\n@app.route('/integrity_verification', methods=['POST'])\ndef integrity_verification():\n    start_time = time.time()\n    if 'file' not in request.files:\n        return jsonify({'error': 'No file part'}), 400\n    file = request.files['file']\n    file.save(file.filename)\n    image_path = '/kaggle/working/'+file.filename\n    fm = featureMapExtractor(image_path)\n    data = request.get_json()\n    feature_map = data['feature_map']\n    integrity = None\n    if fm == feature_map:\n        integrity = True\n    else:\n        integrity = False\n    end_time = time.time()\n    print(\"Total time for integrity verification:\", end_time - start_time)\n    return jsonify({'integrity_status': integrity})\n\n@app.route('/get_fm_en_ipfs', methods=['POST'])\ndef get_fm_en_ipfs():\n    start_time = time.time()\n    \n    if 'file' not in request.files:\n        return jsonify({'error': 'No file part'}), 400\n    file = request.files['file']\n    file.save(file.filename)\n    cmp_start_time = time.time()\n    img = Image.open(\"/kaggle/working/\"+file.filename)\n    img.save('compressed_'+file.filename, quality=100, optimize=True, format='JPEG')\n    image_path_cmp = '/kaggle/working/compressed_'+file.filename\n    cmp_end_time = time.time()\n    print(\"compresstion time:\", cmp_end_time - cmp_start_time)\n    \n    fm_start_time = time.time()\n    fm = featureMapExtractor(image_path_cmp)\n    fm_end_time = time.time()\n    print(\"featureMapExtractor time:\", fm_end_time - fm_start_time)\n    \n    encrypt_start_time = time.time()\n    encrypted_img_path, encryption_key = encrypt_image(image_path_cmp)\n    encrypt_end_time = time.time()\n    print(\"encrypt_image time:\", encrypt_end_time - encrypt_start_time)\n    \n    upload_start_time = time.time()\n    ipfs_hash = upload_to_pinata_ipfs(encrypted_img_path)\n    upload_end_time = time.time()\n    print(\"upload_to_pinata_ipfs time:\", upload_end_time - upload_start_time)\n    \n    encryption_key_hex = encryption_key.hex()\n    original_encryption_key = binascii.unhexlify(encryption_key_hex)\n    print(fm.tolist())\n    end_time = time.time()\n    print(\"Total time for get_fm_en_ipfs:\", end_time - start_time)\n    \n    return jsonify({'feature_map': fm.tolist(), 'encryption_key': encryption_key_hex, 'ipfs_hash': ipfs_hash})\n\n@app.route('/get_decrypted_image', methods=['POST'])\ndef get_decrypted_image():\n    start_time = time.time()\n    \n    data = request.get_json()\n    if not data or 'ipfs_url' not in data or 'encryption_key' not in data:\n        return jsonify({'error': 'IPFS URL and encryption key are required'}), 400\n    ipfs_url = data['ipfs_url']\n    encryption_key = data['encryption_key']\n    \n    encryption_key = binascii.unhexlify(encryption_key)\n    \n    download_start_time = time.time()\n    encrypted_image_path = download_from_ipfs(ipfs_url)\n    download_end_time = time.time()\n    print(\"download_from_ipfs time:\", download_end_time - download_start_time)\n    \n    decrypt_start_time = time.time()\n    decrypted_img_path = decrypt_image(encryption_key, encrypted_image_path)\n    decrypt_end_time = time.time()\n    print(\"decrypt_image time:\", decrypt_end_time - decrypt_start_time)\n    \n    try:\n        with open(decrypted_img_path, \"rb\") as image_file:\n            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n        end_time = time.time()\n        print(\"Total time for get_decrypted_image:\", end_time - start_time)\n        \n        return jsonify({'decrypted_image': encoded_string})\n    except Exception as e:\n        return jsonify({'error': str(e)}), 500\n    \nif __name__ == '__main__':\n    app.run(port=port)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}